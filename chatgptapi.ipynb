{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"C:/Users/Home/ChatGPT_API_Joke_Bot/Secret/secret.txt\",\"r\").read().strip('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\n\\nThe circumference of the moon is approximately 10,921 km.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1679466071,\n",
      "  \"id\": \"chatcmpl-6wm8NP4NCZtbMv8F1xKJWI13EL6ua\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 14,\n",
      "    \"prompt_tokens\": 17,\n",
      "    \"total_tokens\": 31\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"What is the circumference of the moon in km?\"}]\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "The circumference of the moon is approximately 10,921 km.\n"
     ]
    }
   ],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users's input was What is the circumference of the moon in km?\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "user_input = input(\">: \")\n",
    "\n",
    "print(\"Users's input was\", user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"user\",\"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The circumference of the moon is approximately 10,921 km.\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = message_history,\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"assistant\",\"content\": reply_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was What is better, baseball or basketball\n",
      "\n",
      "As an AI language model, I cannot have a personal preference or opinion. However, some people may enjoy baseball and others may enjoy basketball based on their personal interests and preferences. It is subjective and varies from person to person.\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\">: \")\n",
    "print(\"User's input was\", user_input)\n",
    "print()\n",
    "message_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = message_history,\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was Which is better to measure ingredients, grams or teaspoons?\n",
      "\n",
      "\n",
      "\n",
      "As an AI language model, I do not have the ability to form preferences or opinions. However, the choice of metric to measure ingredients depends on the specific context and the type of ingredient being measured. \n",
      "\n",
      "For example, for small volumes or weights of spices or flavorings, teaspoons or tablespoons are more commonly used, while for larger amounts of ingredients such as flour, sugar, or liquids, grams or milliliters are more precise and accurate. It's important to follow the recipe instructions and use the measurement units indicated to ensure consistent and accurate results.\n",
      "\n",
      "User's input was \n",
      "\n",
      "As an AI language model, I do not have personal opinions or preferences. However, some people might choose to measure ingredients in grams because it is a more precise and accurate method of measurement than using teaspoons or other volumetric measurements. Measuring by weight eliminates the variability of measurement caused by differences in the density and amount of air in the ingredient. Additionally, measuring in grams can make it easier to scale recipes up or down depending on the desired yield. However, measuring in teaspoons or other volume measurements can be more convenient for small amounts of spices or flavorings. Ultimately, the choice of measurement method depends on the context and the specific ingredient being measured.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "\n",
    "def chat(inp, role = \"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": inp})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = message_history,\n",
    "    )\n",
    "\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": reply_content})\n",
    "    return reply_content\n",
    "\n",
    "for i in range(2):\n",
    "    user_input = input(\">: \")\n",
    "    print(\"User's input was\", user_input)\n",
    "    print()\n",
    "    chat(user_input)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
